{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIQ7yytMziSC"
      },
      "source": [
        "## Deep Learning Facial Expression Model Building\n",
        "Ethan Assefa, Thomas Burrell, Tatev Gomstyan\n",
        "\n",
        "## Environment Set-Up\n",
        "\n",
        "Begin by loading packages needed and creating pipeline to bring in data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "20Mpk-OTzhRX"
      },
      "outputs": [],
      "source": [
        "# necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm  # Import tqdm for the progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldi4Pz2d5kgA",
        "outputId": "b341ebed-fe41-45d4-d452-e0e97bfb0553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available: NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and set the default device to GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'GPU is available: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('GPU is not available, using CPU instead.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_4EiSIb0Kzj"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = ' DS6050 Final Project/face_expression_archive/images/train'\n",
        "TEST_DIR = ' DS6050 Final Project/face_expression_archive/images/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5oSl1zYx0t4z"
      },
      "outputs": [],
      "source": [
        "# collects image file and organizes for processing\n",
        "def createdataframe(dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    for label in os.listdir(dir):\n",
        "        for imagename in os.listdir(os.path.join(dir, label)):\n",
        "            image_paths.append(os.path.join(dir, label, imagename))\n",
        "            labels.append(label)\n",
        "        print(label, \"completed\")\n",
        "    return image_paths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W07gssht0ud3",
        "outputId": "720b0f71-7e3f-4695-d748-32d24a6c70ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry completed\n",
            "disgust completed\n",
            "fear completed\n",
            "happy completed\n",
            "neutral completed\n",
            "sad completed\n",
            "surprise completed\n",
            "                                               image  label\n",
            "0  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n",
            "1  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n",
            "2  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n"
          ]
        }
      ],
      "source": [
        "# Brings in training data\n",
        "train = pd.DataFrame()\n",
        "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
        "print(train.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYDtLeuD0ye4",
        "outputId": "7d13aa98-8287-42f3-fe43-351eda7049d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry completed\n",
            "disgust completed\n",
            "fear completed\n",
            "happy completed\n",
            "neutral completed\n",
            "sad completed\n",
            "surprise completed\n",
            "                                               image  label\n",
            "0  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n",
            "1  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n",
            "2  C:/Users/affes/OneDrive/Documents/UVA SDS Spri...  angry\n"
          ]
        }
      ],
      "source": [
        "# Brings in testing data\n",
        "test = pd.DataFrame()\n",
        "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
        "print(test.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to check\n",
        "path_to_check = ' DS6050 Final Project/face_expression_archive/images/train'\n",
        "\n",
        "# Iterate over files and try to open them\n",
        "for dirpath, dirnames, filenames in os.walk(path_to_check):\n",
        "    for filename in filenames:\n",
        "        filepath = os.path.join(dirpath, filename)\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                pass  # File can be opened\n",
        "        except Exception as e:\n",
        "            print(f\"Cannot open file {filepath}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9M6wy0u00he"
      },
      "source": [
        "## Preprocessing Data\n",
        "\n",
        "Two key methods for preprocessing:\n",
        "\n",
        "1. Data augmentation\n",
        "  - This helps to create a more robust model by artificially expanding the dataset using variations of the training data through transformations like rotation, zoom, flips, etc. It's particularly effective in scenarios like facial expression recognition, where expressions can vary widely in different lighting, angles, and facial positions.\n",
        "2. Feature Standardization\n",
        "  - Standardizing images by scaling pixel values to have mean 0 and variance 1 helps in speeding up the training process and leads to faster convergence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2AcDVqFhQF4n"
      },
      "outputs": [],
      "source": [
        "# Define transformations to the training data for data augmentation\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(), # Randomly flip images horizontally\n",
        "    transforms.RandomRotation(10), # Randomly rotate images by up to 10 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Randomly jitter color\n",
        "    transforms.RandomResizedCrop(224), # Randomly crop and resize images to 224x224\n",
        "    transforms.ToTensor(), # Convert images to tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Standardize images\n",
        "])\n",
        "\n",
        "# Function to create specific emotion dataset:\n",
        "def prepare_emotion_dataset(dataframe, target_emotion):\n",
        "    # Create hard copy of dataframe\n",
        "    ouputs = dataframe.copy()\n",
        "    # target_emotion should be the encoded label for the desired emotion\n",
        "    # Add a new binary column for the target emotion\n",
        "    ouputs['target'] = (ouputs['label'] == target_emotion).astype(int)\n",
        "    return ouputs\n",
        "\n",
        "# Class for DataLoader setup, use the 'target' column for labels\n",
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx, 0]  # Where first column is image path\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.dataframe.iloc[idx, 2]  # Where 'target' is in the third column\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QGjdHlCpbmx0"
      },
      "outputs": [],
      "source": [
        "# Before having the emotion-specific models, would need to have the dataset with all labels numerically coded\n",
        "# Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "# Properly encode the labels\n",
        "train['label'] = label_encoder.fit_transform(train['label'])\n",
        "test['label'] = label_encoder.transform(test['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "cZ0Ihky_iQ10",
        "outputId": "46df707a-c1a2-4229-d8df-11fd3a0c4b23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded Train Labels: ['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "Test Data after Encoding: [0 1 2 3 4 5 6]\n",
            "Encoding for angry: 0\n",
            "Encoding for disgust: 1\n",
            "Encoding for fear: 2\n",
            "Encoding for happy: 3\n",
            "Encoding for neutral: 4\n",
            "Encoding for sad: 5\n",
            "Encoding for surprise: 6\n"
          ]
        }
      ],
      "source": [
        "# Check encoded labels\n",
        "print(\"Encoded Train Labels:\", label_encoder.classes_)\n",
        "print(\"Test Data after Encoding:\", test['label'].unique())\n",
        "\n",
        "# Create list of emotions\n",
        "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# Further checks before preparing datasets\n",
        "for emotion in emotions:\n",
        "    emotion_label = label_encoder.transform([emotion])[0]\n",
        "    print(f\"Encoding for {emotion}: {emotion_label}\")\n",
        "    # Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "znj2IH-xQR33"
      },
      "outputs": [],
      "source": [
        "# Create function for piecemeal training and test sets (one for each emotion)\n",
        "def piecemeal_train_test(emotion, batch_num):\n",
        "    # Determine emotion coding\n",
        "    emotion_lbl = label_encoder.transform([emotion])[0]\n",
        "\n",
        "    # Train data\n",
        "    train_dataset = prepare_emotion_dataset(train, emotion_lbl)\n",
        "    train_dataset = FacialExpressionDataset(dataframe=train_dataset, transform=data_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_num, shuffle=True)\n",
        "\n",
        "    # Test data\n",
        "    test_dataset = prepare_emotion_dataset(test, emotion_lbl)\n",
        "    test_dataset = FacialExpressionDataset(dataframe=test_dataset, transform=transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_num, shuffle=False)\n",
        "    \n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4SrfXHY-k-4"
      },
      "source": [
        "## Model Generation\n",
        "We create individual emotion models to focus on learning specific emotions, then we create a multi-class model for all emotions to focus on general learning. These will all be combined in an ensemble model later on. Three methods incorporated in the model architecture:\n",
        "\n",
        "1. Dropout layer\n",
        "  - Dropout is a form of regularization technique that helps prevent overfitting in neural networks. It does this by randomly setting a fraction of input units to 0 at each update during training time, which helps to make the model more robust as it cannot rely on any single set of features.\n",
        "2. Regularization Techniques\n",
        "  - Besides dropout, other regularization techniques include L1 and L2 regularization, which add a penalty on the size of coefficients. L2 regularization (weight decay in deep learning) is especially common.\n",
        "3. Batch Normalization\n",
        "  - This technique normalizes the input layer by adjusting and scaling activations. It allows each layer of a network to learn by itself a little bit more independently of other layers, which can speed up training and improve the final performance of the network.\n",
        "\n",
        "### Individual Emotion Models\n",
        "We begin by creating, training, and testing seven seperate models - one for each emotion class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class for the emotion model assuming a batch size of 32\n",
        "class EmotionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmotionModel, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32), # Batch normalization\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25), # 25% dropout\n",
        "            \n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25) # 25% dropout\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64 * 56 * 56, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5), # 50% dropout\n",
        "            nn.Linear(256, 1)  # Binary classification for specific emotion vs not\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Function to evaluate the model on the test set\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for evaluation, which saves memory and computations\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float()\n",
        "            outputs = model(images)\n",
        "            predicted = torch.sigmoid(outputs).round()  # Apply sigmoid and round to get binary predictions\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for emotion: angry\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: angry - Accuracy: 86.41%\n",
            "Training for emotion: disgust\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: disgust - Accuracy: 98.43%\n",
            "Training for emotion: fear\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: fear - Accuracy: 85.59%\n",
            "Training for emotion: happy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: happy - Accuracy: 74.17%\n",
            "Training for emotion: neutral\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: neutral - Accuracy: 82.79%\n",
            "Training for emotion: sad\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: sad - Accuracy: 83.88%\n",
            "Training for emotion: surprise\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for emotion: surprise - Accuracy: 88.72%\n"
          ]
        }
      ],
      "source": [
        "# Set device as GPU if avaliable\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define parameters\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "learn_rate = 0.00001\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# Define the 7 emotion categories\n",
        "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "\n",
        "# Create dictionary of models\n",
        "models = {}\n",
        "# Dictionary to store accuracies\n",
        "accuracies = {}\n",
        "\n",
        "# Automate training for each emotion\n",
        "for emotion in emotions:\n",
        "    train_loader, test_loader = piecemeal_train_test(emotion, batch_size)\n",
        "    model = EmotionModel().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    print(f\"Training for emotion: {emotion}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)  # Progress bar for each epoch\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device).float()\n",
        "            outputs = model(images)\n",
        "            labels = labels.unsqueeze(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=epoch_loss/len(train_loader))  # Update progress bar with average loss\n",
        "\n",
        "    # After training, evaluate on the test set\n",
        "    accuracy = evaluate_model(model, test_loader, device)\n",
        "    accuracies[emotion] = accuracy\n",
        "    print(f\"Testing for emotion: {emotion} - Accuracy: {accuracy:.2f}%\")\n",
        "    \n",
        "    # Add emotion model to dictionary for all the emotions\n",
        "    models[emotion] = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi-class General Model\n",
        "We then create a single model for classifying all seven emotions for general learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiClassCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(MultiClassCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(64),  # Batch normalization layer after convolution\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.3),  # Dropout layer after pooling\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(128),  # Batch normalization layer after convolution\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.4),  # Increased dropout rate for deeper layers\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),  # Batch normalization layer after convolution\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(p=0.5)  # Further increased dropout rate for even deeper layers\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 28 * 28, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),  # Dropout before the final layer\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FullTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx, 0]  # Assuming the first column is images\n",
        "        image = Image.open(img_path).convert('RGB')  # Convert the image file path to a PIL image\n",
        "        label = self.dataframe.iloc[idx, 1]  # Assuming the second column is labels\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Transformations\n",
        "test_transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "# Create the DataLoader for the full test set\n",
        "full_test_dataset = FullTestDataset(test, transform=test_transform)\n",
        "full_test_loader = DataLoader(full_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Create the DataLoader for the full train set\n",
        "full_train_dataset = FullTestDataset(train, transform=data_transforms)\n",
        "full_train_loader = DataLoader(full_train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the multi-class model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing accuracy: 42.15%\n"
          ]
        }
      ],
      "source": [
        "# Set device as GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define training parameters\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "learn_rate = 0.001\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# Prepare your data loaders\n",
        "#full_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "#full_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Instantiate and set up the model\n",
        "multimodel = MultiClassCNN(num_classes=7).to(device)\n",
        "optimizer = torch.optim.Adam(multimodel.parameters(), lr=learn_rate, weight_decay=weight_decay) # Added weight decay for L2 regularization\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the multi-class model\")\n",
        "for epoch in range(num_epochs):\n",
        "    multimodel.train()\n",
        "    epoch_loss = 0\n",
        "    progress_bar = tqdm(full_train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device).long()  # Convert labels to long\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = multimodel(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=epoch_loss / len(full_train_loader))\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(model, full_test_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in full_test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f\"Testing accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "evaluate_model(multimodel, full_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the full test set: 42.15%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_0</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>True Label</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.143050</td>\n",
              "      <td>0.013495</td>\n",
              "      <td>0.131041</td>\n",
              "      <td>0.231398</td>\n",
              "      <td>0.186566</td>\n",
              "      <td>0.234237</td>\n",
              "      <td>0.060213</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.123385</td>\n",
              "      <td>0.016752</td>\n",
              "      <td>0.149738</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.265359</td>\n",
              "      <td>0.259672</td>\n",
              "      <td>0.083847</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.127057</td>\n",
              "      <td>0.020709</td>\n",
              "      <td>0.158809</td>\n",
              "      <td>0.264156</td>\n",
              "      <td>0.183652</td>\n",
              "      <td>0.164566</td>\n",
              "      <td>0.081050</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.194167</td>\n",
              "      <td>0.033447</td>\n",
              "      <td>0.170624</td>\n",
              "      <td>0.029215</td>\n",
              "      <td>0.287957</td>\n",
              "      <td>0.244955</td>\n",
              "      <td>0.039636</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.288995</td>\n",
              "      <td>0.039059</td>\n",
              "      <td>0.170677</td>\n",
              "      <td>0.046442</td>\n",
              "      <td>0.189329</td>\n",
              "      <td>0.209056</td>\n",
              "      <td>0.056441</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7061</th>\n",
              "      <td>0.010065</td>\n",
              "      <td>0.001867</td>\n",
              "      <td>0.108806</td>\n",
              "      <td>0.005673</td>\n",
              "      <td>0.007977</td>\n",
              "      <td>0.007648</td>\n",
              "      <td>0.857963</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7062</th>\n",
              "      <td>0.135805</td>\n",
              "      <td>0.014832</td>\n",
              "      <td>0.134449</td>\n",
              "      <td>0.315266</td>\n",
              "      <td>0.158279</td>\n",
              "      <td>0.195255</td>\n",
              "      <td>0.046114</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7063</th>\n",
              "      <td>0.140139</td>\n",
              "      <td>0.015285</td>\n",
              "      <td>0.214504</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.132359</td>\n",
              "      <td>0.152732</td>\n",
              "      <td>0.228381</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7064</th>\n",
              "      <td>0.141508</td>\n",
              "      <td>0.014625</td>\n",
              "      <td>0.143188</td>\n",
              "      <td>0.201710</td>\n",
              "      <td>0.208087</td>\n",
              "      <td>0.221334</td>\n",
              "      <td>0.069548</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7065</th>\n",
              "      <td>0.056584</td>\n",
              "      <td>0.006479</td>\n",
              "      <td>0.302017</td>\n",
              "      <td>0.008160</td>\n",
              "      <td>0.055677</td>\n",
              "      <td>0.047944</td>\n",
              "      <td>0.523140</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7066 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Class_0   Class_1   Class_2   Class_3   Class_4   Class_5   Class_6  \\\n",
              "0     0.143050  0.013495  0.131041  0.231398  0.186566  0.234237  0.060213   \n",
              "1     0.123385  0.016752  0.149738  0.101247  0.265359  0.259672  0.083847   \n",
              "2     0.127057  0.020709  0.158809  0.264156  0.183652  0.164566  0.081050   \n",
              "3     0.194167  0.033447  0.170624  0.029215  0.287957  0.244955  0.039636   \n",
              "4     0.288995  0.039059  0.170677  0.046442  0.189329  0.209056  0.056441   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7061  0.010065  0.001867  0.108806  0.005673  0.007977  0.007648  0.857963   \n",
              "7062  0.135805  0.014832  0.134449  0.315266  0.158279  0.195255  0.046114   \n",
              "7063  0.140139  0.015285  0.214504  0.116600  0.132359  0.152732  0.228381   \n",
              "7064  0.141508  0.014625  0.143188  0.201710  0.208087  0.221334  0.069548   \n",
              "7065  0.056584  0.006479  0.302017  0.008160  0.055677  0.047944  0.523140   \n",
              "\n",
              "      True Label  Predicted Label  \n",
              "0              0                5  \n",
              "1              0                4  \n",
              "2              0                3  \n",
              "3              0                4  \n",
              "4              0                0  \n",
              "...          ...              ...  \n",
              "7061           6                6  \n",
              "7062           6                3  \n",
              "7063           6                6  \n",
              "7064           6                5  \n",
              "7065           6                6  \n",
              "\n",
              "[7066 rows x 9 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_on_full_test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    all_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)  # Getting outputs from the model\n",
        "\n",
        "            # Assuming outputs are logits, compute probabilities and indices\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            predicted_indices = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "            # Storing results\n",
        "            predicted_labels.extend(predicted_indices.cpu().tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "            all_probabilities.extend(probabilities.cpu().numpy())  # Collecting probabilities for analysis\n",
        "\n",
        "    # Creating a DataFrame for probabilities\n",
        "    probabilities_df = pd.DataFrame(all_probabilities, columns=[f\"Class_{i}\" for i in range(probabilities.shape[1])])\n",
        "    probabilities_df['True Label'] = true_labels\n",
        "    probabilities_df['Predicted Label'] = predicted_labels\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    print(f\"Accuracy of the model on the full test set: {accuracy * 100:.2f}%\")\n",
        "    return accuracy, probabilities_df\n",
        "\n",
        "# Usage\n",
        "accuracy, probabilities_df = evaluate_on_full_test(multimodel, full_test_loader, device)\n",
        "#print(probabilities_df.head())\n",
        "\n",
        "probabilities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the multiclass model\n",
        "torch.save(multimodel.state_dict(), f' DS6050 Final Project/multiclass_model_v2.pth')\n",
        "# Full model details\n",
        "torch.save({\n",
        "        'model_state_dict': multimodel.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, f' DS6050 Final Project/multiclass_model_v2_full.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ensemble Methods for Models\n",
        "In ensemble learning, the goal is to combine different models to improve the overall performance and reliability of predictions. Two common methods for combining models in an ensemble are voting mechanisms and averaging approaches. Each has its own benefits and drawbacks, and the choice of which to use can depend on the specifics of the problem and the models involved.\n",
        "\n",
        "Average Mechanism: This involves averaging the outputs of the models, typically their predicted probabilities (after applying a sigmoid function). The emotion corresponding to the highest average probability is chosen. This method can provide a more nuanced view as it considers the confidence levels of each model's predictions. \n",
        "\n",
        "### Ensemble Model (Single-Emotion and Multi-Class Models)\n",
        "This hybrid ensemble model can potentially improve performance by balancing the broad learning capability of a multi-class model with the focused insights of binary classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiSingleEmotionEnsemble(nn.Module):\n",
        "    def __init__(self, emotion_models, multi_class_model, weights):\n",
        "        super(MultiSingleEmotionEnsemble, self).__init__()\n",
        "        self.emotion_models = emotion_models  # Dictionary of binary models\n",
        "        self.multi_class_model = multi_class_model  # Multi-class model\n",
        "        self.weights = weights  # Weights for combining probabilities\n",
        "        self.emotions = list(emotion_models.keys())  # List of emotion names\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-class model probabilities\n",
        "        self.multi_class_model.eval()\n",
        "        with torch.no_grad():\n",
        "            mc_probs = torch.softmax(self.multi_class_model(x), dim=1) * self.weights['multi_class']\n",
        "\n",
        "        # Binary model probabilities\n",
        "        combined_probs = mc_probs\n",
        "        for emotion, model in self.emotion_models.items():\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = torch.sigmoid(model(x)).unsqueeze(1)  # Ensure it's the right shape\n",
        "                combined_probs[:, self.emotions.index(emotion)] += output.squeeze() * self.weights['binary'][emotion]\n",
        "\n",
        "        # Normalize probabilities to ensure they sum to 1 across classes\n",
        "        combined_probs /= combined_probs.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Find the index of the highest probability for each image/sample\n",
        "        predicted_indices = torch.argmax(combined_probs, dim=1)\n",
        "        probabilities_df = pd.DataFrame(combined_probs.detach().cpu().numpy(), columns=self.emotions)\n",
        "\n",
        "        return predicted_indices, probabilities_df\n",
        "\n",
        "# Weights configuration\n",
        "weights = {\n",
        "    'multi_class': 0.2,\n",
        "    'binary': {emotion: 0.8 / len(models) for emotion in models}  # Evenly distribute the remaining weight\n",
        "}\n",
        "\n",
        "# Create ensemble model including the multi-class model\n",
        "mult_sing_ensemble_model = MultiSingleEmotionEnsemble(models, model, weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the ensemble model on the full test set: 45.08%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angry</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>happy</th>\n",
              "      <th>neutral</th>\n",
              "      <th>sad</th>\n",
              "      <th>surprise</th>\n",
              "      <th>True Label</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.160657</td>\n",
              "      <td>0.014053</td>\n",
              "      <td>0.114196</td>\n",
              "      <td>0.148429</td>\n",
              "      <td>0.261302</td>\n",
              "      <td>0.209226</td>\n",
              "      <td>0.092137</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.144125</td>\n",
              "      <td>0.018937</td>\n",
              "      <td>0.253209</td>\n",
              "      <td>0.038171</td>\n",
              "      <td>0.157364</td>\n",
              "      <td>0.173942</td>\n",
              "      <td>0.214251</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.150291</td>\n",
              "      <td>0.043025</td>\n",
              "      <td>0.172330</td>\n",
              "      <td>0.173178</td>\n",
              "      <td>0.152052</td>\n",
              "      <td>0.135016</td>\n",
              "      <td>0.174108</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.284856</td>\n",
              "      <td>0.041949</td>\n",
              "      <td>0.201904</td>\n",
              "      <td>0.052841</td>\n",
              "      <td>0.139574</td>\n",
              "      <td>0.222749</td>\n",
              "      <td>0.056127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.263945</td>\n",
              "      <td>0.028938</td>\n",
              "      <td>0.166002</td>\n",
              "      <td>0.051797</td>\n",
              "      <td>0.162665</td>\n",
              "      <td>0.172206</td>\n",
              "      <td>0.154447</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7061</th>\n",
              "      <td>0.069161</td>\n",
              "      <td>0.005777</td>\n",
              "      <td>0.143585</td>\n",
              "      <td>0.033606</td>\n",
              "      <td>0.062796</td>\n",
              "      <td>0.030331</td>\n",
              "      <td>0.654744</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7062</th>\n",
              "      <td>0.123276</td>\n",
              "      <td>0.016987</td>\n",
              "      <td>0.082290</td>\n",
              "      <td>0.407092</td>\n",
              "      <td>0.140708</td>\n",
              "      <td>0.137811</td>\n",
              "      <td>0.091835</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7063</th>\n",
              "      <td>0.138383</td>\n",
              "      <td>0.007934</td>\n",
              "      <td>0.184557</td>\n",
              "      <td>0.075307</td>\n",
              "      <td>0.090566</td>\n",
              "      <td>0.118299</td>\n",
              "      <td>0.384953</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7064</th>\n",
              "      <td>0.120304</td>\n",
              "      <td>0.012295</td>\n",
              "      <td>0.153919</td>\n",
              "      <td>0.120829</td>\n",
              "      <td>0.251153</td>\n",
              "      <td>0.171304</td>\n",
              "      <td>0.170194</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7065</th>\n",
              "      <td>0.112156</td>\n",
              "      <td>0.027519</td>\n",
              "      <td>0.242690</td>\n",
              "      <td>0.064593</td>\n",
              "      <td>0.057379</td>\n",
              "      <td>0.092336</td>\n",
              "      <td>0.403326</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7066 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         angry   disgust      fear     happy   neutral       sad  surprise  \\\n",
              "0     0.160657  0.014053  0.114196  0.148429  0.261302  0.209226  0.092137   \n",
              "1     0.144125  0.018937  0.253209  0.038171  0.157364  0.173942  0.214251   \n",
              "2     0.150291  0.043025  0.172330  0.173178  0.152052  0.135016  0.174108   \n",
              "3     0.284856  0.041949  0.201904  0.052841  0.139574  0.222749  0.056127   \n",
              "4     0.263945  0.028938  0.166002  0.051797  0.162665  0.172206  0.154447   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7061  0.069161  0.005777  0.143585  0.033606  0.062796  0.030331  0.654744   \n",
              "7062  0.123276  0.016987  0.082290  0.407092  0.140708  0.137811  0.091835   \n",
              "7063  0.138383  0.007934  0.184557  0.075307  0.090566  0.118299  0.384953   \n",
              "7064  0.120304  0.012295  0.153919  0.120829  0.251153  0.171304  0.170194   \n",
              "7065  0.112156  0.027519  0.242690  0.064593  0.057379  0.092336  0.403326   \n",
              "\n",
              "      True Label  Predicted Label  \n",
              "0              0                4  \n",
              "1              0                2  \n",
              "2              0                6  \n",
              "3              0                0  \n",
              "4              0                0  \n",
              "...          ...              ...  \n",
              "7061           6                6  \n",
              "7062           6                3  \n",
              "7063           6                6  \n",
              "7064           6                4  \n",
              "7065           6                6  \n",
              "\n",
              "[7066 rows x 9 columns]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_ensemble_on_full_test(ensemble_model, test_loader, device):\n",
        "    ensemble_model.to(device)\n",
        "    ensemble_model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    all_probabilities_df = pd.DataFrame()  # Initialize an empty DataFrame to store all probabilities\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            predicted_indices, probabilities_df = ensemble_model(images)  # Get predictions and probabilities\n",
        "            predicted_indices = predicted_indices.cpu().tolist()\n",
        "            predicted_labels.extend(predicted_indices)\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            # Add true and predicted labels to the probabilities DataFrame\n",
        "            probabilities_df['True Label'] = labels.tolist()\n",
        "            probabilities_df['Predicted Label'] = predicted_indices\n",
        "            \n",
        "            # Concatenate this batch's results with the main DataFrame\n",
        "            all_probabilities_df = pd.concat([all_probabilities_df, probabilities_df], ignore_index=True)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    return accuracy, all_probabilities_df\n",
        "\n",
        "# Evaluation\n",
        "accuracy, probabilities_df = evaluate_ensemble_on_full_test(mult_sing_ensemble_model, full_test_loader, device)\n",
        "print(f\"Accuracy of the ensemble model on the full test set: {accuracy*100:.2f}%\")\n",
        "probabilities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the probabilities_df as csv\n",
        "probabilities_df.to_csv(' DS6050 Final Project/multi_sing_ensemble_probabilities.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the multiclass model\n",
        "torch.save(model.state_dict(), f' DS6050 Final Project/multiclass_model.pth')\n",
        "# Full model details\n",
        "torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, f' DS6050 Final Project/multiclass_model_full.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ensemble Model (Single-Emotion Models Only)\n",
        "Given that each model is trained specifically to recognize the presence of one emotion, the average mechanism might be more appropriate. It leverages the confidence levels of each model in predicting the presence of its respective emotion, allowing for a more balanced decision-making process when multiple models might be slightly confident."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EmotionEnsemble(nn.Module):\n",
        "    def __init__(self, emotion_models):\n",
        "        super(EmotionEnsemble, self).__init__()\n",
        "        self.emotion_models = emotion_models  # A dictionary of models, each trained for a specific emotion\n",
        "        self.emotions = list(emotion_models.keys())  # Keep a list of emotion names\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Store each model's output (probabilities)\n",
        "        outputs = []\n",
        "        for emotion, model in self.emotion_models.items():\n",
        "            model.eval()  # Ensure the model is in eval mode\n",
        "            with torch.no_grad():\n",
        "                output = torch.sigmoid(model(x))  # Apply sigmoid to convert logits to probabilities\n",
        "                outputs.append(output)\n",
        "\n",
        "        # Stack all model outputs vertically and squeeze to remove extra dimensions\n",
        "        outputs = torch.stack(outputs, dim=1).squeeze(2)  # Remove the extra dimension\n",
        "        \n",
        "        # Create DataFrame for outputs to visualize probabilities easily\n",
        "        probabilities_df = pd.DataFrame(outputs.detach().cpu().numpy(), columns=self.emotions)\n",
        "\n",
        "        # Find the index of the highest probability for each image/sample\n",
        "        predicted_indices = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        return predicted_indices, probabilities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming 'models' is a dictionary with each emotion as a key and its respective trained model as the value\n",
        "ensemble_model = EmotionEnsemble(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the ensemble model on the full test set: 40.16%\n"
          ]
        }
      ],
      "source": [
        "# Create method to evalaute ensemble on the full test set\n",
        "def evaluate_ensemble_on_full_test(ensemble_model, test_loader, device):\n",
        "    ensemble_model.to(device)\n",
        "    ensemble_model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    all_probabilities_df = pd.DataFrame()  # Initialize an empty DataFrame to store all probabilities\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            predicted_indices, probabilities_df = ensemble_model(images)  # Get predictions and probabilities\n",
        "            predicted_indices = predicted_indices.cpu().tolist()\n",
        "            predicted_labels.extend(predicted_indices)\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            # Add true and predicted labels to the probabilities DataFrame\n",
        "            probabilities_df['True Label'] = labels.tolist()\n",
        "            probabilities_df['Predicted Label'] = predicted_indices\n",
        "            \n",
        "            # Concatenate this batch's results with the main DataFrame\n",
        "            all_probabilities_df = pd.concat([all_probabilities_df, probabilities_df], ignore_index=True)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    return accuracy, all_probabilities_df\n",
        "\n",
        "# Assuming 'ensemble_model' is your ensemble model and 'device' is your computation device\n",
        "accuracy, probabilities_df = evaluate_ensemble_on_full_test(ensemble_model, full_test_loader, device)\n",
        "print(f\"Accuracy of the ensemble model on the full test set: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>angry</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>happy</th>\n",
              "      <th>neutral</th>\n",
              "      <th>sad</th>\n",
              "      <th>surprise</th>\n",
              "      <th>True Label</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.280022</td>\n",
              "      <td>0.037069</td>\n",
              "      <td>0.181467</td>\n",
              "      <td>0.300229</td>\n",
              "      <td>0.306570</td>\n",
              "      <td>0.287575</td>\n",
              "      <td>0.185023</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.282884</td>\n",
              "      <td>0.049432</td>\n",
              "      <td>0.364739</td>\n",
              "      <td>0.048894</td>\n",
              "      <td>0.186987</td>\n",
              "      <td>0.227994</td>\n",
              "      <td>0.417891</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.247936</td>\n",
              "      <td>0.063992</td>\n",
              "      <td>0.302449</td>\n",
              "      <td>0.296723</td>\n",
              "      <td>0.225163</td>\n",
              "      <td>0.202377</td>\n",
              "      <td>0.424013</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.297718</td>\n",
              "      <td>0.049174</td>\n",
              "      <td>0.234457</td>\n",
              "      <td>0.102684</td>\n",
              "      <td>0.205566</td>\n",
              "      <td>0.245725</td>\n",
              "      <td>0.112290</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.316794</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>0.214052</td>\n",
              "      <td>0.089469</td>\n",
              "      <td>0.230756</td>\n",
              "      <td>0.187097</td>\n",
              "      <td>0.399400</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7061</th>\n",
              "      <td>0.217757</td>\n",
              "      <td>0.018629</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.099596</td>\n",
              "      <td>0.193861</td>\n",
              "      <td>0.093551</td>\n",
              "      <td>0.496610</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7062</th>\n",
              "      <td>0.265075</td>\n",
              "      <td>0.042124</td>\n",
              "      <td>0.161999</td>\n",
              "      <td>0.264774</td>\n",
              "      <td>0.330143</td>\n",
              "      <td>0.321558</td>\n",
              "      <td>0.254835</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7063</th>\n",
              "      <td>0.259494</td>\n",
              "      <td>0.021643</td>\n",
              "      <td>0.219369</td>\n",
              "      <td>0.148707</td>\n",
              "      <td>0.147564</td>\n",
              "      <td>0.220532</td>\n",
              "      <td>0.358364</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7064</th>\n",
              "      <td>0.205053</td>\n",
              "      <td>0.035980</td>\n",
              "      <td>0.279591</td>\n",
              "      <td>0.182811</td>\n",
              "      <td>0.285887</td>\n",
              "      <td>0.196963</td>\n",
              "      <td>0.341128</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7065</th>\n",
              "      <td>0.248595</td>\n",
              "      <td>0.083294</td>\n",
              "      <td>0.332244</td>\n",
              "      <td>0.095491</td>\n",
              "      <td>0.131890</td>\n",
              "      <td>0.220920</td>\n",
              "      <td>0.387213</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7066 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         angry   disgust      fear     happy   neutral       sad  surprise  \\\n",
              "0     0.280022  0.037069  0.181467  0.300229  0.306570  0.287575  0.185023   \n",
              "1     0.282884  0.049432  0.364739  0.048894  0.186987  0.227994  0.417891   \n",
              "2     0.247936  0.063992  0.302449  0.296723  0.225163  0.202377  0.424013   \n",
              "3     0.297718  0.049174  0.234457  0.102684  0.205566  0.245725  0.112290   \n",
              "4     0.316794  0.034164  0.214052  0.089469  0.230756  0.187097  0.399400   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7061  0.217757  0.018629  0.360000  0.099596  0.193861  0.093551  0.496610   \n",
              "7062  0.265075  0.042124  0.161999  0.264774  0.330143  0.321558  0.254835   \n",
              "7063  0.259494  0.021643  0.219369  0.148707  0.147564  0.220532  0.358364   \n",
              "7064  0.205053  0.035980  0.279591  0.182811  0.285887  0.196963  0.341128   \n",
              "7065  0.248595  0.083294  0.332244  0.095491  0.131890  0.220920  0.387213   \n",
              "\n",
              "      True Label  Predicted Label  \n",
              "0              0                4  \n",
              "1              0                6  \n",
              "2              0                6  \n",
              "3              0                0  \n",
              "4              0                6  \n",
              "...          ...              ...  \n",
              "7061           6                6  \n",
              "7062           6                4  \n",
              "7063           6                6  \n",
              "7064           6                6  \n",
              "7065           6                6  \n",
              "\n",
              "[7066 rows x 9 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "probabilities_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the probabilities_df as csv\n",
        "probabilities_df.to_csv(' DS6050 Final Project/sing_only_ensemble_probabilities.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save individual models\n",
        "for emotion, model in models.items():\n",
        "    torch.save(model.state_dict(), f' DS6050 Final Project/{emotion}_model.pth')\n",
        "\n",
        "# Optionally save other training parameters\n",
        "for emotion, model in models.items():\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, f' DS6050 Final Project/{emotion}_model_full.pth')\n",
        "\n",
        "# Save the ensemble model\n",
        "# Note: Ensure that the ensemble model is initialized and used in a way that it can be reconstructed from individual models\n",
        "torch.save({emotion: model.state_dict() for emotion, model in models.items()}, ' DS6050 Final Project/ensemble_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stacking\n",
        "Simple averaging for the ensemble model hasn't worked too well for our accuracy. We now try model stacking, where we use a second-level model (the stacker) to combine the predictions of multiple base models. Stacking might yield better performance, as it can robustly integrate learnings from multiple diverse models.\n",
        "- We implement cross-validation to better utilize our limited data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_stacking_features(models, loader, device):\n",
        "    stack_x = []\n",
        "    stack_y = []\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        features = []\n",
        "        for model in models.values():\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = torch.sigmoid(model(images)).cpu().numpy()  # Ensure output is in [0,1]\n",
        "                # Ensure the output is always reshaped to (batch_size, 1)\n",
        "                output = output.reshape(-1, 1)  # Reshape to avoid dimension mismatch\n",
        "                features.append(output)\n",
        "        # Stack features horizontally\n",
        "        features = np.hstack(features)  # This should now be safe\n",
        "        stack_x.append(features)\n",
        "        stack_y.append(labels.numpy())\n",
        "    return np.vstack(stack_x), np.hstack(stack_y)\n",
        "\n",
        "# Create the DataLoader for the full train set\n",
        "full_train_dataset = FullTestDataset(train, transform=data_transforms)\n",
        "full_train_loader = DataLoader(full_train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Assuming `full_train_loader` is your DataLoader for the training data\n",
        "stack_x, stack_y = create_stacking_features(models, full_train_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming `model_accuracies` is a dict with model names as keys and their validation accuracies as values\n",
        "weights = np.array([model_accuracies[model_name] for model_name in sorted(model_accuracies)])\n",
        "weighted_features = features * weights / weights.sum()  # Normalize weights to sum to 1\n",
        "\n",
        "stack_x.append(weighted_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated accuracy scores: [0.29746045 0.30391341 0.30745212 0.30918176 0.2989798  0.30314387]\n",
            "Mean CV accuracy: 30.34%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "stacker = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "cv_scores = cross_val_score(stacker, stack_x, stack_y, cv=6)  # Using 6-fold cross-validation\n",
        "print(f\"Cross-validated accuracy scores: {cv_scores}\")\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated accuracy scores: [0.30412157 0.30974188 0.3143214  0.31355403 0.30897356 0.30439309]\n",
            "Mean CV accuracy: 30.92%\n"
          ]
        }
      ],
      "source": [
        "# Initialize the logistic regression stacker\n",
        "stacker = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(stacker, stack_x, stack_y, cv=6)  # Using 5-fold cross-validation\n",
        "print(f\"Cross-validated accuracy scores: {cv_scores}\")\n",
        "print(f\"Mean CV accuracy: {np.mean(cv_scores) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the stacking features into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(stack_x, stack_y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy of stacker model: 31.64%\n"
          ]
        }
      ],
      "source": [
        "stacker = LogisticRegression(max_iter=1000)\n",
        "stacker.fit(X_train, y_train)\n",
        "\n",
        "# Validate the stacker model\n",
        "stacker_score = stacker.score(X_val, y_val)\n",
        "print(f\"Validation accuracy of stacker model: {stacker_score * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy of the stacked model: 40.83%\n"
          ]
        }
      ],
      "source": [
        "# Prepare test set features for the stacker\n",
        "test_stack_x, test_stack_y = create_stacking_features(models, full_test_loader, device)\n",
        "\n",
        "# Predict and evaluate\n",
        "test_predictions = stacker.predict(test_stack_x)\n",
        "test_accuracy = accuracy_score(test_stack_y, test_predictions)\n",
        "print(f\"Test accuracy of the stacked model: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Models\n",
        "Saving and loading models in PyTorch is straightforward using torch.save and torch.load. This is especially useful for large models or when training takes a significant amount of time. You can save not just the model weights but also the optimizer state, epoch details, and any other metadata you might find useful for resuming training or for inference later.\n",
        "\n",
        "Here we save our individual models as well as the ensemble model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save individual models\n",
        "for emotion, model in models.items():\n",
        "    torch.save(model.state_dict(), f' DS6050 Final Project/{emotion}_model.pth')\n",
        "\n",
        "# Optionally save other training parameters\n",
        "for emotion, model in models.items():\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "    }, f' DS6050 Final Project/{emotion}_model_full.pth')\n",
        "\n",
        "# Save the ensemble model\n",
        "# Note: Ensure that the ensemble model is initialized and used in a way that it can be reconstructed from individual models\n",
        "torch.save({emotion: model.state_dict() for emotion, model in models.items()}, ' DS6050 Final Project/ensemble_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Models (if needed)\n",
        "If needed later, we can now load the model objects from our environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load individual models\n",
        "loaded_models = {}\n",
        "for emotion in emotions:\n",
        "    model = EmotionModel()  # Ensure the model architecture is defined or imported\n",
        "    model.load_state_dict(torch.load(f' DS6050 Final Project/{emotion}_model.pth'))\n",
        "    model.eval()\n",
        "    loaded_models[emotion] = model\n",
        "\n",
        "# Load the ensemble model\n",
        "ensemble_state_dicts = torch.load(' DS6050 Final Project/ensemble_model.pth')\n",
        "ensemble_models = {emotion: EmotionModel().load_state_dict(state) for emotion, state in ensemble_state_dicts.items()}\n",
        "ensemble_model = EmotionEnsemble(ensemble_models)\n",
        "ensemble_model.eval()  # Set to evaluation mode if only for inference"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
